{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1fvn8oFZ-yPVfitvkVgSlKkUnyN49y4Dk",
      "authorship_tag": "ABX9TyP2ajcqOp8G8GsiysVeEAnS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anandpuntambekar/Binary_Image_Classiff_cats_dogs/blob/master/Hangman_attempt_5_recap.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import collections\n",
        "#torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n"
      ],
      "metadata": {
        "id": "iTItmV9TaApK"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Tj6jE2WkWMe8"
      },
      "outputs": [],
      "source": [
        "#1 - not working\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "import re\n",
        "import collections\n",
        "#torch.autograd.set_detect_anomaly(True)\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        # First hidden layer\n",
        "        self.fc1 = nn.Linear(input_dim, 64)  # Increased neurons to 64\n",
        "        # Second hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)  # Introduced an additional layer with 64 neurons\n",
        "        # Third hidden layer\n",
        "        self.fc3 = nn.Linear(64, 48)  # Introduced another layer with 48 neurons\n",
        "        # Output layer\n",
        "        self.fc4 = nn.Linear(48, output_dim)\n",
        "\n",
        "        # Initialize weights with Kaiming Initialization for LeakyReLU\n",
        "        '''\n",
        "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
        "        '''\n",
        "        # Define LeakyReLU activation function\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "\n",
        "\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.95\n",
        "        self.learning_rate = 3*0.0001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "\n",
        "        # Change word encoding to put -1 if the word is not required or out of scope\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [-1] * (29 - len(word))\n",
        "\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        # sugession\n",
        "        # If you have gussed first word correctly - add a single state to represent what was the first word\n",
        "        # If you have gussed last word correctly - add a single state to represent what was the last word\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "              target = reward + self.gamma * torch.argmax(self.model(next_state)).item()\n",
        "          '''\n",
        "          target_q_values = self.model(state)\n",
        "\n",
        "          # Prepare data for CrossEntropy loss\n",
        "          action_idx = ord(action) - 97\n",
        "          loss = self.criterion(target_q_values, torch.tensor([action_idx]).to(device))\n",
        "          '''\n",
        "          predicted_q_values = self.model(state)\n",
        "          target_q_values = predicted_q_values.clone().detach()\n",
        "          action_idx = ord(action) - 97\n",
        "          target_q_values[0][action_idx] = target\n",
        "          loss = nn.MSELoss()(predicted_q_values, target_q_values)\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def guess(self, word): # word input example: \"_ p p _ e \"\n",
        "        ###############################################\n",
        "        # Replace with your own \"guess\" function here #\n",
        "        ###############################################\n",
        "\n",
        "        # clean the word so that we strip away the space characters\n",
        "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
        "        clean_word = word[::2].replace(\"_\",\".\")\n",
        "\n",
        "        # find length of passed word\n",
        "        len_word = len(clean_word)\n",
        "\n",
        "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
        "        current_dictionary = self.word_list\n",
        "        new_dictionary = []\n",
        "\n",
        "        # iterate through all of the words in the old plausible dictionary\n",
        "        for dict_word in current_dictionary:\n",
        "            # continue if the word is not of the appropriate length\n",
        "            if len(dict_word) != len_word:\n",
        "                continue\n",
        "\n",
        "            # if dictionary word is a possible match then add it to the current dictionary\n",
        "            if re.match(clean_word,dict_word):\n",
        "                new_dictionary.append(dict_word)\n",
        "\n",
        "        # overwrite old possible words dictionary with updated version\n",
        "        self.current_dictionary = new_dictionary\n",
        "\n",
        "\n",
        "        # count occurrence of all characters in possible word matches\n",
        "        full_dict_string = \"\".join(new_dictionary)\n",
        "\n",
        "        c = collections.Counter(full_dict_string)\n",
        "        sorted_letter_count = c.most_common()\n",
        "\n",
        "        guess_letter = '!'\n",
        "\n",
        "        # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "        for letter,instance_count in sorted_letter_count:\n",
        "            if letter not in self.guessed_letters:\n",
        "                guess_letter = letter\n",
        "                break\n",
        "\n",
        "        # if no word matches in training dictionary, default back to ordering of full dictionary\n",
        "        if guess_letter == '!':\n",
        "            sorted_letter_count = self.full_dictionary_common_letter_sorted\n",
        "            for letter,instance_count in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        return guess_letter\n",
        "\n",
        "    def choose_action(self, state, use_guess_function=False):\n",
        "        if use_guess_function:\n",
        "            # Transform state back to the word representation\n",
        "            word = ''.join(['_' if char == 1 else char for char in state[0][-34:-5].tolist()])  # adjusted indices based on your state representation\n",
        "            return self.guess(word)\n",
        "        else:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "              return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = nn.functional.softmax(self.model(state), dim=-1)  # Apply softmax here\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32, guess_epochs=2000):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            use_guess_function = _ < guess_epochs\n",
        "            use_guess_function=False\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "            ## If you have gussed the complete word get a + 10 reward\n",
        "            ## if you have reached the limit of incorrect gusses you get a -10\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #action = self.choose_action(state)\n",
        "                action = self.choose_action(state, use_guess_function)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "                # Check if the entire word has been guessed\n",
        "                if \"_\" not in guessed_word:\n",
        "                    reward = 10\n",
        "                    done = True\n",
        "\n",
        "                # Check if the limit of incorrect guesses has been reached\n",
        "                if incorrect_guesses >= self.MAX_CHANCES:\n",
        "                    reward = -10\n",
        "                    done = True\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              #q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "              q_values = nn.functional.softmax(self.model(state), dim=-1).detach().cpu().numpy()\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#2 not working\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        # First hidden layer\n",
        "        self.fc1 = nn.Linear(input_dim, 64)  # Increased neurons to 64\n",
        "        # Second hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)  # Introduced an additional layer with 64 neurons\n",
        "        # Third hidden layer\n",
        "        self.fc3 = nn.Linear(64, 48)  # Introduced another layer with 48 neurons\n",
        "        # Output layer\n",
        "        self.fc4 = nn.Linear(48, output_dim)\n",
        "\n",
        "        # Initialize weights with Kaiming Initialization for LeakyReLU\n",
        "        '''\n",
        "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
        "        '''\n",
        "        # Define LeakyReLU activation function\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        return self.fc4(x)\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.95\n",
        "        self.learning_rate = 3*0.0001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "\n",
        "        # Change word encoding to put -1 if the word is not required or out of scope\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [-1] * (29 - len(word))\n",
        "\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        # sugession\n",
        "        # If you have gussed first word correctly - add a single state to represent what was the first word\n",
        "        # If you have gussed last word correctly - add a single state to represent what was the last word\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "              target = reward + self.gamma * torch.argmax(self.model(next_state)).item()\n",
        "          '''\n",
        "          target_q_values = self.model(state)\n",
        "\n",
        "          # Prepare data for CrossEntropy loss\n",
        "          action_idx = ord(action) - 97\n",
        "          loss = self.criterion(target_q_values, torch.tensor([action_idx]).to(device))\n",
        "          '''\n",
        "          predicted_q_values = self.model(state)\n",
        "          target_q_values = predicted_q_values.clone().detach()\n",
        "          action_idx = ord(action) - 97\n",
        "          target_q_values[0][action_idx] = target\n",
        "          loss = nn.MSELoss()(predicted_q_values, target_q_values)\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def guess(self, word): # word input example: \"_ p p _ e \"\n",
        "        ###############################################\n",
        "        # Replace with your own \"guess\" function here #\n",
        "        ###############################################\n",
        "\n",
        "        # clean the word so that we strip away the space characters\n",
        "        # replace \"_\" with \".\" as \".\" indicates any character in regular expressions\n",
        "        clean_word = word[::2].replace(\"_\",\".\")\n",
        "\n",
        "        # find length of passed word\n",
        "        len_word = len(clean_word)\n",
        "\n",
        "        # grab current dictionary of possible words from self object, initialize new possible words dictionary to empty\n",
        "        current_dictionary = self.word_list\n",
        "        new_dictionary = []\n",
        "\n",
        "        # iterate through all of the words in the old plausible dictionary\n",
        "        for dict_word in current_dictionary:\n",
        "            # continue if the word is not of the appropriate length\n",
        "            if len(dict_word) != len_word:\n",
        "                continue\n",
        "\n",
        "            # if dictionary word is a possible match then add it to the current dictionary\n",
        "            if re.match(clean_word,dict_word):\n",
        "                new_dictionary.append(dict_word)\n",
        "\n",
        "        # overwrite old possible words dictionary with updated version\n",
        "        self.current_dictionary = new_dictionary\n",
        "\n",
        "\n",
        "        # count occurrence of all characters in possible word matches\n",
        "        full_dict_string = \"\".join(new_dictionary)\n",
        "\n",
        "        c = collections.Counter(full_dict_string)\n",
        "        sorted_letter_count = c.most_common()\n",
        "\n",
        "        guess_letter = '!'\n",
        "\n",
        "        # return most frequently occurring letter in all possible words that hasn't been guessed yet\n",
        "        for letter,instance_count in sorted_letter_count:\n",
        "            if letter not in self.guessed_letters:\n",
        "                guess_letter = letter\n",
        "                break\n",
        "\n",
        "        # if no word matches in training dictionary, default back to ordering of full dictionary\n",
        "        if guess_letter == '!':\n",
        "            sorted_letter_count = self.full_dictionary_common_letter_sorted\n",
        "            for letter,instance_count in sorted_letter_count:\n",
        "                if letter not in self.guessed_letters:\n",
        "                    guess_letter = letter\n",
        "                    break\n",
        "\n",
        "        return guess_letter\n",
        "\n",
        "    def choose_action(self, state, use_guess_function=False):\n",
        "        if use_guess_function:\n",
        "            # Transform state back to the word representation\n",
        "            word = ''.join(['_' if char == 1 else char for char in state[0][-34:-5].tolist()])  # adjusted indices based on your state representation\n",
        "            return self.guess(word)\n",
        "        else:\n",
        "            if np.random.rand() <= self.epsilon:\n",
        "              return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = nn.functional.softmax(self.model(state), dim=-1)  # Apply softmax here\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32, guess_epochs=2000):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            use_guess_function = _ < guess_epochs\n",
        "            use_guess_function=False\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "            ## If you have gussed the complete word get a + 10 reward\n",
        "            ## if you have reached the limit of incorrect gusses you get a -10\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #action = self.choose_action(state)\n",
        "                action = self.choose_action(state, use_guess_function)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "                # Check if the entire word has been guessed\n",
        "                if \"_\" not in guessed_word:\n",
        "                    reward = 10\n",
        "                    done = True\n",
        "\n",
        "                # Check if the limit of incorrect guesses has been reached\n",
        "                if incorrect_guesses >= self.MAX_CHANCES:\n",
        "                    reward = -10\n",
        "                    done = True\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              #q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "              q_values = nn.functional.softmax(self.model(state), dim=-1).detach().cpu().numpy()\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ],
      "metadata": {
        "id": "IAAHFxVSXKHJ"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#3 working not so well\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from collections import deque\n",
        "import matplotlib.pyplot as plt\n",
        "import random\n",
        "\n",
        "\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "\n",
        "        # First hidden layer\n",
        "        self.fc1 = nn.Linear(input_dim, 64)  # Increased neurons to 64\n",
        "        # Second hidden layer\n",
        "        self.fc2 = nn.Linear(64, 64)  # Introduced an additional layer with 64 neurons\n",
        "        # Third hidden layer\n",
        "        self.fc3 = nn.Linear(64, 48)  # Introduced another layer with 48 neurons\n",
        "        # Output layer\n",
        "        self.fc4 = nn.Linear(48, output_dim)\n",
        "\n",
        "        # Initialize weights with Kaiming Initialization for LeakyReLU\n",
        "        '''\n",
        "        init.kaiming_normal_(self.fc1.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc2.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc3.weight, nonlinearity='leaky_relu')\n",
        "        init.kaiming_normal_(self.fc4.weight, nonlinearity='leaky_relu')\n",
        "        '''\n",
        "        # Define LeakyReLU activation function\n",
        "        self.leaky_relu = nn.LeakyReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.leaky_relu(self.fc1(x))\n",
        "        x = self.leaky_relu(self.fc2(x))\n",
        "        x = self.leaky_relu(self.fc3(x))\n",
        "        return nn.functional.softmax(self.fc4(x), dim=-1)  # Softmax added here\n",
        "\n",
        "\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.95\n",
        "        self.learning_rate = 3*0.0001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.CrossEntropyLoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "\n",
        "        # Change word encoding to put -1 if the word is not required or out of scope\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [-1] * (29 - len(word))\n",
        "\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        # sugession\n",
        "        # If you have gussed first word correctly - add a single state to represent what was the first word\n",
        "        # If you have gussed last word correctly - add a single state to represent what was the last word\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = random.sample(self.memory, batch_size)\n",
        "        for state, action, reward, next_state, done in minibatch:\n",
        "          target = reward\n",
        "          if not done:\n",
        "              target = reward + self.gamma * torch.argmax(self.model(next_state)).item()\n",
        "          target_q_values = self.model(state)\n",
        "\n",
        "          # Prepare data for CrossEntropy loss\n",
        "          action_idx = ord(action) - 97\n",
        "          loss = self.criterion(target_q_values, torch.tensor([action_idx]).to(device))\n",
        "\n",
        "          self.optimizer.zero_grad()\n",
        "          loss.backward()\n",
        "          self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            #print('Epoch:',_)\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "            ## If you have gussed the complete word get a + 10 reward\n",
        "            ## if you have reached the limit of incorrect gusses you get a -10\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "                # Check if the entire word has been guessed\n",
        "                if \"_\" not in guessed_word:\n",
        "                    reward = 10\n",
        "                    done = True\n",
        "\n",
        "                # Check if the limit of incorrect guesses has been reached\n",
        "                if incorrect_guesses >= self.MAX_CHANCES:\n",
        "                    reward = -10\n",
        "                    done = True\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            #target_q_values[0][ord(action) - 97] = target\n",
        "            #target_q_values = self.model(state).clone()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values = target_q_values.clone()\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ],
      "metadata": {
        "id": "HsfNg5PKXo4r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#def build_dictionary( full_dictionary_location):\n",
        "text_file = open(dictionary_file_location,\"r\")\n",
        "full_dictionary = text_file.read().splitlines()\n",
        "text_file.close()\n",
        "full_dictionary\n",
        "\n",
        "type(full_dictionary)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "chLaiwCrWZFK",
        "outputId": "d40fe0ea-a2da-48d4-b3bf-400dba5082db"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#4 working\n",
        "class QNetwork(nn.Module):\n",
        "    def __init__(self, input_dim, output_dim):\n",
        "        super(QNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 24)\n",
        "        self.fc2 = nn.Linear(24, 24)\n",
        "        self.fc3 = nn.Linear(24, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = torch.relu(self.fc2(x))\n",
        "        return self.fc3(x)\n",
        "\n",
        "\n",
        "class HangmanDQL:\n",
        "    def __init__(self, word_list):\n",
        "        self.word_list = word_list\n",
        "        self.epsilon = 0.2\n",
        "        self.memory = deque(maxlen=2000)\n",
        "        self.gamma = 0.9\n",
        "        self.epsilon_min = 0.01\n",
        "        self.epsilon_decay = 0.995\n",
        "        self.learning_rate = 0.001 #0.00055 #0.001\n",
        "        self.model = QNetwork(26 + 29+5, 26).to(device)\n",
        "        self.optimizer = optim.Adam(self.model.parameters(), lr=self.learning_rate)\n",
        "        self.criterion = nn.MSELoss()\n",
        "        self.MAX_CHANCES = 10\n",
        "\n",
        "    def get_state(self, word, used_letters,incorrect_guesses):\n",
        "        state = [1 if char in used_letters else 0 for char in 'abcdefghijklmnopqrstuvwxyz']\n",
        "        #word_encoding = [1 if char == \"_\" else 0 for char in word]\n",
        "        word_encoding = [1 if char == \"_\" else 0 for char in word] + [0] * (29 - len(word))\n",
        "        # a. Length of the word being guessed\n",
        "        word_length = len(word)\n",
        "\n",
        "        # b. Count of correct letters guessed in the current word state\n",
        "        correct_letter_count = sum(word.count(letter) for letter in set(word) if letter != '_')\n",
        "\n",
        "        # c. Total positions correctly guessed\n",
        "        correct_positions = len(word) - word_encoding.count(1)\n",
        "\n",
        "        # d. Total guesses pending\n",
        "        guesses_pending = len(word) - correct_positions\n",
        "\n",
        "        # e. Total chances pending\n",
        "        chances_pending = self.MAX_CHANCES - incorrect_guesses\n",
        "\n",
        "        state_representation = state + word_encoding\n",
        "        #print(\"State representation length:\", len(state_representation))\n",
        "\n",
        "        state_representation = state + word_encoding + [word_length, correct_letter_count, correct_positions, guesses_pending, chances_pending]\n",
        "\n",
        "        return torch.tensor(state_representation, dtype=torch.float32).unsqueeze(0).to(device)\n",
        "\n",
        "    def choose_action(self, state):\n",
        "        if np.random.rand() <= self.epsilon:\n",
        "            return chr(np.random.choice(range(97, 123)))\n",
        "        with torch.no_grad():\n",
        "            q_values = self.model(state)\n",
        "        return chr(torch.argmax(q_values).item() + 97)\n",
        "\n",
        "    def remember(self, state, action, reward, next_state, done):\n",
        "        self.memory.append((state, action, reward, next_state, done))\n",
        "\n",
        "    def replay(self, batch_size):\n",
        "        minibatch = np.random.choice(len(self.memory), batch_size)\n",
        "        for i in minibatch:\n",
        "            state, action, reward, next_state, done = self.memory[i]\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        if self.epsilon > self.epsilon_min:\n",
        "            self.epsilon *= self.epsilon_decay\n",
        "\n",
        "    def train(self, epochs=1000, batch_size=32):\n",
        "\n",
        "        for _ in range(epochs):\n",
        "            #print('Epoch:',_)\n",
        "            print(f'Training Epoch: {_ + 1}/{epochs}')\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses=0\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "                    incorrect_guesses += 1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "\n",
        "                if len(self.memory) > batch_size:\n",
        "                    self.replay(batch_size)\n",
        "            success_rate = self.test(games=500)\n",
        "            #print(f\"Success Rate after Epoch {_ + 1}: {success_rate:.2%}\")\n",
        "\n",
        "    def find_learning_rate(self, init_value=1e-8, final_value=10., beta=0.98):\n",
        "        num = len(self.memory) - 1\n",
        "        mult = (final_value / init_value) ** (1/num)\n",
        "        lr = init_value\n",
        "        self.optimizer.param_groups[0]['lr'] = lr\n",
        "        avg_loss = 0.\n",
        "        best_loss = 0.\n",
        "        batch_num = 0\n",
        "        losses = []\n",
        "        log_lrs = []\n",
        "        for data in self.memory:\n",
        "            batch_num += 1\n",
        "            # Get a mini-batch of training data\n",
        "            state, action, reward, next_state, done = data\n",
        "            target = reward\n",
        "            if not done:\n",
        "                target = reward + self.gamma * torch.max(self.model(next_state)).item()\n",
        "            target_q_values = self.model(state)\n",
        "            target_q_values[0][ord(action) - 97] = target\n",
        "            predicted_q_values = self.model(state)\n",
        "            loss = self.criterion(predicted_q_values, target_q_values)\n",
        "\n",
        "            # Smooth the average and compute the smoothed loss\n",
        "            avg_loss = beta * avg_loss + (1-beta) *loss.item()\n",
        "            smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
        "\n",
        "            # Stop if the loss is exploding\n",
        "            if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
        "                return log_lrs, losses\n",
        "            # Record the best loss\n",
        "            if smoothed_loss < best_loss or batch_num==1:\n",
        "                best_loss = smoothed_loss\n",
        "\n",
        "            # Store the values\n",
        "            losses.append(smoothed_loss)\n",
        "            log_lrs.append(np.log10(lr))\n",
        "\n",
        "            # Update the learning rate\n",
        "            lr *= mult\n",
        "            self.optimizer.param_groups[0]['lr'] = lr\n",
        "\n",
        "            # Perform the optimization step\n",
        "            self.optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            self.optimizer.step()\n",
        "\n",
        "        return log_lrs, losses\n",
        "\n",
        "    def plot_lr_finder(self, log_lrs, losses):\n",
        "        plt.plot(log_lrs, losses)\n",
        "        plt.xlabel(\"Log10 Learning Rate\")\n",
        "        plt.ylabel(\"Loss\")\n",
        "        plt.title(\"Learning Rate Finder\")\n",
        "        plt.show()\n",
        "\n",
        "    def populate_memory(self, games=500):\n",
        "        for _ in range(games):\n",
        "            word = np.random.choice(self.word_list)\n",
        "            guessed_word = [\"_\"] * len(word)\n",
        "            used_letters = []\n",
        "            incorrect_guesses = 0  # Initialize it here\n",
        "            done = False\n",
        "\n",
        "            while not done:\n",
        "                state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                #print(\"State shape:\", state.shape)\n",
        "                action = self.choose_action(state)\n",
        "                used_letters.append(action)\n",
        "\n",
        "                if action in word:\n",
        "                    for i, letter in enumerate(word):\n",
        "                        if letter == action:\n",
        "                            guessed_word[i] = action\n",
        "                    reward = 1\n",
        "                else:\n",
        "                    reward = -1\n",
        "\n",
        "                if \"_\" not in guessed_word or len(used_letters) > 10:\n",
        "                    done = True\n",
        "\n",
        "                next_state = self.get_state(\"\".join(guessed_word), used_letters,incorrect_guesses)\n",
        "                self.remember(state, action, reward, next_state, done)\n",
        "                #print(state.shape)\n",
        "                #print(26 + len(max(self.word_list, key=len)))\n",
        "\n",
        "    def test(self, games=100):\n",
        "      total_success = 0\n",
        "\n",
        "      for _ in range(games):\n",
        "          word = np.random.choice(self.word_list)\n",
        "          guessed_word = [\"_\"] * len(word)\n",
        "          used_letters = []\n",
        "          incorrect_guesses = 0\n",
        "          game_over = False\n",
        "\n",
        "          while not game_over:\n",
        "              state = self.get_state(\"\".join(guessed_word), used_letters, incorrect_guesses)\n",
        "              q_values = self.model(state).detach().cpu().numpy()  # Get Q-values for actions\n",
        "\n",
        "              # Exclude already used letters\n",
        "              for used_letter in used_letters:\n",
        "                  q_values[0][ord(used_letter) - 97] = -np.inf\n",
        "\n",
        "              action = chr(np.argmax(q_values) + 97)\n",
        "              used_letters.append(action)\n",
        "\n",
        "              if action in word:\n",
        "                  for i, letter in enumerate(word):\n",
        "                      if letter == action:\n",
        "                          guessed_word[i] = action\n",
        "              else:\n",
        "                incorrect_guesses += 1  # Increment the counter if the guess was incorrect\n",
        "\n",
        "\n",
        "              game_over = \"_\" not in guessed_word or len(used_letters) > 10\n",
        "\n",
        "          # Check if the game was a success\n",
        "          if \"_\" not in guessed_word:\n",
        "              total_success += 1\n",
        "\n",
        "      print(f\"Success rate: {total_success/games:.2%}\")\n",
        "      return total_success"
      ],
      "metadata": {
        "id": "3EbfzU6CZ0sT"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "dictionary_file_location ='/content/drive/MyDrive/Anand_Trexquant/words_250000_train.txt'\n",
        "#def build_dictionary( full_dictionary_location):\n",
        "text_file = open(dictionary_file_location,\"r\")\n",
        "full_dictionary = text_file.read().splitlines()\n",
        "text_file.close()\n",
        "full_dictionary\n",
        "\n",
        "type(full_dictionary)\n",
        "word_list = [\"ability\", \"absence\", \"academy\", \"account\", \"accuracy\", \"activity\",\n",
        "             \"actually\", \"addition\", \"address\", \"admission\", \"advantage\", \"advice\",\n",
        "             \"adviser\", \"affect\", \"afternoon\", \"situation\", \"associate\", \"attention\",\n",
        "             \"attitude\", \"attribute\", \"audience\", \"authority\", \"available\", \"awareness\",\n",
        "             \"beautiful\", \"certainly\", \"challenge\", \"character\", \"chocolate\", \"collection\",\n",
        "             \"commercial\", \"committee\", \"community\", \"completely\", \"complex\", \"component\",\n",
        "             \"conclusion\", \"condition\", \"conference\", \"confidence\", \"connection\", \"consciousness\",\n",
        "             \"consider\", \"consistent\", \"constant\", \"construction\", \"contain\", \"content\",\n",
        "             \"contribute\", \"contribution\", \"control\", \"conversation\", \"cooperation\", \"corporation\",\n",
        "             \"cultural\", \"currently\", \"dangerous\", \"definition\", \"demonstrate\", \"department\",\n",
        "             \"dependent\", \"designer\", \"determine\", \"developer\", \"development\", \"difference\",\n",
        "             \"difficulty\", \"dimension\", \"direction\", \"director\", \"disappear\", \"discipline\",\n",
        "             \"discovery\", \"discussion\", \"distribute\", \"distribution\", \"diversity\", \"education\",\n",
        "             \"efficiency\", \"electronic\", \"employment\", \"encourage\", \"engineer\", \"entertainment\",\n",
        "             \"environment\", \"especially\", \"establish\", \"evaluation\", \"eventually\", \"everybody\",\n",
        "             \"everything\", \"evidence\", \"exactly\", \"examination\"]\n",
        "\n",
        "agent = HangmanDQL(full_dictionary)\n",
        "agent.populate_memory(games=1000)\n",
        "log_lrs, losses = agent.find_learning_rate()\n",
        "agent.plot_lr_finder(log_lrs, losses)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "U8IX2AbTWc0O",
        "outputId": "d811bc13-56dd-46e9-d886-8f70ef2925cc"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent = HangmanDQL(full_dictionary)\n",
        "agent.train(epochs=5000)\n",
        "success_count = agent.test(games=100)\n",
        "print(success_count)"
      ],
      "metadata": {
        "id": "uA85Z6M7Wf-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}